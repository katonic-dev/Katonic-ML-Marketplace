{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incident Forecast for IT Infrastructure\n",
    "\n",
    "This is a trainable algorithm which trains on user provided historical incident data and builds & saves a deep learning model which is a representation of the historical data,once the model is generated, the solution can be used to predict next three most probable incidents. \n",
    "\n",
    "Mphasis DeepInsights Incident forecasting is a solution to forecast most probable next three incidents/errors in IT infrastructure. The solution helps in better incident management and lower downtime through proactive actions.\n",
    "\n",
    "\n",
    "This sample notebook shows you how to deploy Mphasis InfraGraf Incident Forecast for IT Infrastructure using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Incident Forecast for IT Infrastructure. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "    3. Make sure to install below mentioned python libraries before running this notebook\n",
    "    \n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Usage Instruction](#2.-Usage-Instruction)\n",
    "3. [Training](#3.-Training) \n",
    "4. [Sample Data](#4.-Sample-Data)\n",
    "5. [Perform batch inference](#5.-Perform-batch-inference)\n",
    "6. [Create an endpoint and perform real-time inference](#6.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "7. [Clean-up](#7.-Clean-up)\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the algorithm listing page **Incident Forecast for IT Infrastructure**\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Usage Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed solution has these 2 steps:\n",
    "1: The system trains on user provided historical incident data and builds & saves a deep learning model which is a representation of the historical data.\n",
    "2: Once the model is generated, the solution can be used to predict next three most probable incidents. \n",
    "To achieve this end, the solution deploys the following 2 APIs over AWS Sagemaker:\n",
    "\n",
    "1.Training API: The solution requires historical consecutive incidents along with contextual information as input for training the model.\n",
    "2.Testing API: The solution requires recent historical incidents which would be used for forecasting next three incidents along with contextual information as input (same as training API).\n",
    "## Input\n",
    "Supported content types: `text/csv`\n",
    "** Following are the mandatory inputs for both the APIs:**\n",
    "1.\tIncident Number: Unique ID for each incident\n",
    "2.\tIncident Created Date: Date (MM/DD/YYYY) when Incident occurred.\n",
    "3.\tConfiguration: Category of Incident that occurred.\n",
    "\n",
    "Note: \n",
    "1.\tTwo separate csv input files are required for training and testing.\n",
    "2.\tFor better results please provide at least 2000 consecutive historical incidents for training API.\n",
    "3.\tPlease provide at least 15 recent historical consecutive incidents for test API to forecast next three incidents.\n",
    "  \n",
    "## Output\n",
    "â€¢ Content type: ` text/csv`\n",
    "** The solution generates the following outputs:**\n",
    "Output contains three most probable forecasted incidents.\n",
    "\n",
    "## Invoking endpoint\n",
    "\n",
    "### AWS CLI Command\n",
    "If you are using real time inferencing, please create the endpoint first and then use the  following command to invoke it:\n",
    "\n",
    "``` bash \n",
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type 'text/csv' --region us-east-2 output.csv\n",
    "```\n",
    "Substitute the following parameters:\n",
    "* `\"model-name\"` - name of the inference endpoint where the model is deployed\n",
    "* `file_name` - input csv file name \n",
    "* `text/csv` - content type of the given input \n",
    "* `output.csv` - filename where the inference results are written to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64 \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefixes\n",
    "common_prefix = \"incident_forecasting\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "\n",
    "TRAINING_DATA = TRAINING_WORKDIR + \"/Train_Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Location s3://sagemaker-us-east-2-786796469737/incident_forecasting/training-input-data\n"
     ]
    }
   ],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)\n",
    "print (\"Training Data Location \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from sagemaker.algorithm import AlgorithmEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn ='arn:aws:sagemaker:us-east-2:786796469737:algorithm/incident-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = AlgorithmEstimator(\n",
    "    algorithm_arn=algorithm_arn,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    base_job_name='incident-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the training job using algorithm arn arn:aws:sagemaker:us-east-2:786796469737:algorithm/incident-prediction in region us-east-2\n",
      "2021-01-27 11:19:45 Starting - Starting the training job...\n",
      "2021-01-27 11:20:07 Starting - Launching requested ML instancesProfilerReport-1611746384: InProgress\n",
      "......\n",
      "2021-01-27 11:21:08 Starting - Preparing the instances for training...\n",
      "2021-01-27 11:21:42 Downloading - Downloading input data\n",
      "2021-01-27 11:21:42 Training - Downloading the training image......\n",
      "2021-01-27 11:22:34 Training - Training image download completed. Training in progress.\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-01-27 11:23:30 Uploading - Uploading generated training model\n",
      "2021-01-27 11:24:10 Completed - Training job completed\n",
      "ProfilerReport-1611746384: NoIssuesFound\n",
      "Training seconds: 149\n",
      "Billable seconds: 149\n"
     ]
    }
   ],
   "source": [
    "print (\"Now run the training job using algorithm arn %s in region %s\" % (algorithm_arn, sagemaker_session.boto_region_name))\n",
    "algo.fit({'training': training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Created Date</th>\n",
       "      <th>Configuration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IM30296889</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application Instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30296604</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Incident Collector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30296892</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application Instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30295990</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30297253</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30296215</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Wireless Access Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30294844</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30294579</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application Instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30294247</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application Instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM30293243</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Incident Created Date          Configuration\n",
       "Incident Number                                             \n",
       "IM30296889                 2020-09-09   Application Instance\n",
       "IM30296604                 2020-09-09     Incident Collector\n",
       "IM30296892                 2020-09-09   Application Instance\n",
       "IM30295990                 2020-09-09            Application\n",
       "IM30297253                 2020-09-09                 Router\n",
       "IM30296215                 2020-09-09  Wireless Access Point\n",
       "IM30294844                 2020-09-09                 Router\n",
       "IM30294579                 2020-09-09   Application Instance\n",
       "IM30294247                 2020-09-09   Application Instance\n",
       "IM30293243                 2020-09-09            Application"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "sample_data = pd.read_csv(TRANSFORM_WORKDIR + \"/test.csv\",index_col=0)\n",
    "sample_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/incident_forecasting/batch-inference-input-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/test.csv\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = algo.transformer(1, 'ml.m5.large')\n",
    "transformer.transform(transform_input, content_type='text/csv')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], 'test.csv')\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)\n",
    "response_bytes = response['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketFolder = transformer.output_path.rsplit('/')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"sagemaker-us-east-2-786796469737\"\n",
    "with open('output.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder+'/' + 'test.csv' +'.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Configuration\n",
       "0        Router\n",
       "1        Router\n",
       "2        Switch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_WORKDIR = \"data/output\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "out_csv = pd.read_csv(OUTPUT_WORKDIR + \"/output.csv\",index_col=0)\n",
    "out_csv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='incident-forecasting'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.xlarge'\n",
    "batch_transform_inference_instance_type='ml.m5.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn ='arn:aws:sagemaker:us-east-2:786796469737:algorithm/incident-prediction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=algorithm_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)\n",
    "\n",
    "#Deploy the model\n",
    "predictor = algo.deploy(1, 'ml.m5.xlarge',endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = 'data/transform/test.csv'\n",
    "data_frame = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name 'incident-forecasting' \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type 'text/csv' \\\n",
    "    --region us-east-2 \\\n",
    "    output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Router</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Configuration\n",
       "0        Router\n",
       "1        Router\n",
       "2        Switch"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_csv = pd.read_csv(\"output.csv\",index_col=0)\n",
    "out_csv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
